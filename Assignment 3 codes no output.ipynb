{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "import nltk\n",
    "import random\n",
    "import re\n",
    "documents = [(list(brown.words(fileid)), category)\n",
    "    for category in brown.categories()\n",
    "    for fileid in brown.fileids(category)]\n",
    "random.shuffle(documents)\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "def clean_text_list(text_list):\n",
    "    cleaned_text_list = []\n",
    "    for text in text_list:\n",
    "        text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "        words = text.lower().split()\n",
    "        stopwords_set = set(stopwords.words('english'))\n",
    "        words = [word for word in words if word not in stopwords_set]\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        words = [lemmatizer.lemmatize(word) for word in words]\n",
    "        \n",
    "        # Join the cleaned words back into a single string\n",
    "        cleaned_text = ' '.join(words)\n",
    "        \n",
    "        # Append the cleaned text to the list of cleaned text\n",
    "        cleaned_text_list.append(cleaned_text)\n",
    "    \n",
    "    return cleaned_text_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = nltk.FreqDist(w.lower() for w in brown.words())\n",
    "word_features = list(all_words)[:2000]\n",
    "clean_text_list(word_features) #data cleaning at this steps, after this step we will requires the stem and tokens of words.\n",
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
    "train_features = [(document_features(d), c) for (d,c) in documents]\n",
    "train_set, test_set = featuresets[100:], featuresets[:100]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "brown: The Brown Corpus, a general corpus of texts in English. Categories include adventure, belles_lettres, editorial, fiction, government, hobbies, humor, learned, lore, mystery, news, religion, reviews, romance, science_fiction, and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))\n",
    "classifier.show_most_informative_features(5)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy isn't high enough, only 0.68 here. ï¼ˆDue to random shuffle, the accuracy may be different.) Therefore I gonna enlarge the sample sizes, and use other way\n",
    "to improve the accuracy. Since there are more 2 categories at this corpora, a cross validation method will performe well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier\n",
    "\n",
    "def cross_validation(num_folds, documents):\n",
    "    fold_size = len(documents) // num_folds\n",
    "    accuracies = []\n",
    "    for i in range(num_folds):\n",
    "        test_set = documents[i*fold_size : (i+1)*fold_size]\n",
    "        train_set = documents[:i*fold_size] + documents[(i+1)*fold_size:]\n",
    "        train_feats = [(document_features(doc), category) for (doc, category) in train_set]\n",
    "        test_feats = [(document_features(doc), category) for (doc, category) in test_set]\n",
    "        classifier = nltk.NaiveBayesClassifier.train(train_feats)\n",
    "        accuracy = nltk.classify.accuracy(classifier, test_feats)\n",
    "        accuracies.append(accuracy)\n",
    "    avg_accuracy = sum(accuracies) / num_folds\n",
    "    return avg_accuracy\n",
    "\n",
    "num_folds = 10\n",
    "avg_accuracy = cross_validation(num_folds, documents)\n",
    "print(f'Average accuracy over {num_folds}-fold cross-validation: {avg_accuracy:.2%}')\n",
    "#I run this code several times, but this is the only time cross-validation accuracy is below naive bayes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we define a function cross_validation() that takes as input the number of folds to use, as well as the list of labeled documents. The function randomly shuffles the list of documents and then divides it into num_folds subsets of equal size. For each fold, the function trains a Naive Bayes classifier on the training set and evaluates its accuracy on the test set. It then computes the average accuracy over all folds and returns this value."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the classifier made by me is done, I will show some examples of using this classifier dataset on some newspaper, it can also be used for a whole dataset of corpora as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = \"/Users/apple/Downloads/archive (1)/entertainment\"\n",
    "files = os.listdir(path)\n",
    "document_corpus = []\n",
    "for file in files:\n",
    "   for file in files:\n",
    "    if not os.path.isdir(file):\n",
    "        with open(path+\"/\"+file, encoding=\"latin-1\") as f:\n",
    "            str = f.read()\n",
    "            document_corpus.append(str.encode('latin-1'))\n",
    "print(document_corpus)\n",
    "#open the folders where contain dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example1 = open(\"/Users/apple/Downloads/archive (1)/entertainment/entertainment_1.txt\", \"r\", encoding=\"latin-1\")\n",
    "example2 = open(\"/Users/apple/Downloads/archive (1)/entertainment/entertainment_2.txt\", \"r\", encoding=\"latin-1\")\n",
    "example3 = open(\"/Users/apple/Downloads/archive (1)/entertainment/entertainment_3.txt\", \"r\", encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_features)\n",
    "\n",
    "\n",
    "classification1 = classifier.classify(document_features(clean_text_list(example1)))\n",
    "print(classification1)\n",
    "\n",
    "classification2 = classifier.classify(document_features(clean_text_list(example2)))\n",
    "print(classification1)\n",
    "\n",
    "classification3 = classifier.classify(document_features(clean_text_list(example3)))\n",
    "print(classification1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1 (v3.11.1:a7a450f84a, Dec  6 2022, 15:24:06) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
